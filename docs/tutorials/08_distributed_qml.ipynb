{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66700edb-43a4-4380-b5a1-29d455e6db58",
   "metadata": {},
   "source": [
    "# QML: distributed training\n",
    "\n",
    "Ray train framework allows you to run distributed training algorithms.\n",
    "Quantum Serverless provides a `QiskitTorchTrainer` which allows you to train QNNs in a distributed fashion. Every worker gets it own QPUs (and sessions) to train on. \n",
    "\n",
    "Let's look at example program which will show how to use trainer.\n",
    "\n",
    "\n",
    "First we need to create `train.py` file and start filling it up.\n",
    "Let's import everything we need\n",
    "```python\n",
    "# train.py\n",
    "import ray\n",
    "import torch\n",
    "from qiskit_ibm_runtime import QiskitRuntimeService\n",
    "from ray import train\n",
    "from ray.air import session\n",
    "from torch import nn\n",
    "\n",
    "from quantum_serverless import QuantumServerless, Program\n",
    "from quantum_serverless.library.train.trainer import (\n",
    "    QiskitScalingConfig,\n",
    "    QiskitTorchTrainer,\n",
    "    get_runtime_sessions,\n",
    "    assign_backends,\n",
    "    QiskitTrainerException,\n",
    ")\n",
    "```\n",
    "\n",
    "Then define our training loop\n",
    "```python\n",
    "# train.py\n",
    "\n",
    "def loop(config):\n",
    "    \"\"\"Test training loop.\"\"\"\n",
    "    runtime_session_1, runtime_session_2 = get_runtime_sessions(config)\n",
    "    \n",
    "    print(\"Session for worker:\", [runtime_session_1, runtime_session_2])\n",
    "    print(\"Available backends for worker\", [runtime_session_1.backend(), runtime_session_2.backend()])\n",
    "\n",
    "    # get data, create QNN and run training loop\n",
    "    dataset_shard = session.get_dataset_shard(\"train\")\n",
    "    ...\n",
    "```\n",
    "\n",
    "`get_runtime_sessions` returns qiskit runtime sessions that we can use for our algorithms\n",
    "\n",
    "Let's finish it up with creating serverless context and running `QiskitTorchTrainer`\n",
    "\n",
    "```python\n",
    "    \n",
    "    serverless = QuantumServerless()\n",
    "\n",
    "    with serverless:\n",
    "        train_dataset = ray.data.from_items(\n",
    "            [{\"x\": x, \"y\": 2 * x + 1} for x in range(200)]\n",
    "        )\n",
    "        scaling_config = QiskitScalingConfig(\n",
    "            num_workers=3,\n",
    "            resource_filtering={\n",
    "                \"qpu1\": {\"name\": \"ibmq_qasm_simulator\", \"simulator\": True},\n",
    "                \"qpu2\": {\"name\": \"ibmq_qasm_simulator\", \"simulator\": True},\n",
    "            },\n",
    "            allow_overbooking=True\n",
    "        )\n",
    "        trainer = QiskitTorchTrainer(\n",
    "            train_loop_per_worker=loop,\n",
    "            qiskit_runtime_service_account=runtime_service.active_account(),\n",
    "            scaling_config=scaling_config,\n",
    "            datasets={\"train\": train_dataset},\n",
    "            ...\n",
    "        )\n",
    "        result = trainer.fit()\n",
    "```\n",
    "\n",
    "As you can see we are using `QiskitScalingConfig` to define number or workers and specific requirements for QPUs for each of the workers. \n",
    "\n",
    "`allow_overbooking` flag allows use to use same backend for different workers. In this case it is simulator, that is why we can use it in parallel. In real cases you would be interested in using different QPUs for different workers as it will unlock true parallelism. \n",
    "\n",
    "Full version of program can be found [here](./source_files/train.py).\n",
    "\n",
    "Finally let's run our program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9c199c2-6888-4e7a-a2ac-0186c0ee1c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from quantum_serverless import QuantumServerless, Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ff7b6e1-88d0-4c92-be89-5e78d25d1136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<QuantumServerless | providers [local, docker]>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serverless = QuantumServerless({\n",
    "    \"providers\": [{\n",
    "        \"name\": \"docker\",\n",
    "        \"compute_resource\": {\n",
    "            \"name\": \"docker\",\n",
    "            \"host\": \"localhost\",\n",
    "        }\n",
    "    }]\n",
    "})\n",
    "serverless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ead42c-61e3-4fbb-8932-174373c21785",
   "metadata": {},
   "outputs": [],
   "source": [
    "program = Program(\n",
    "    name=\"train_qnn\",\n",
    "    entrypoint=\"train.py\",\n",
    "    arguments={\n",
    "        \"channel\": \"<CHANNEL>\",\n",
    "        \"token\": \"<TOKEN>\"\n",
    "    },\n",
    "    working_dir=\"./source_files\",\n",
    "    description=\"Train QNN on distributed resources.\"\n",
    ")\n",
    "\n",
    "job = serverless.run_program(program)\n",
    "job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8fb7b6a-7a53-4092-a69c-368ceb1e05b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<JobStatus.SUCCEEDED: 'SUCCEEDED'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job.status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000d5ce1-ed12-4522-8d5b-55f1195e87ea",
   "metadata": {},
   "source": [
    "Let's check logs that we are interested in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89b52c38-e80a-4c1f-93db-ba7bf563a642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session for worker: [<qiskit_ibm_runtime.session.Session object at 0x7fa19709dfd0>, <qiskit_ibm_runtime.session.Session object at 0x7fa22dadb350>]\n",
      "Available backends for worker ['ibmq_qasm_simulator', 'ibmq_qasm_simulator']\n",
      "Session for worker: [<qiskit_ibm_runtime.session.Session object at 0x7faa0cd00f10>, <qiskit_ibm_runtime.session.Session object at 0x7faa0afded90>]\n",
      "Available backends for worker ['ibmq_qasm_simulator', 'ibmq_qasm_simulator']\n",
      "Session for worker: [<qiskit_ibm_runtime.session.Session object at 0x7f16524acb90>, <qiskit_ibm_runtime.session.Session object at 0x7f16524aca10>]\n",
      "Available backends for worker ['ibmq_qasm_simulator', 'ibmq_qasm_simulator']\n",
      "/home/ray/anaconda3/lib/python3.7/site-packages/ray/_private/worker.py:983: UserWarning: len(ctx) is deprecated. Use len(ctx.address_info) instead.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join([log.split(\"0m \")[-1] for log in job.logs().split(\"\\n\")[2:-1]  if \"worker\" in log]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
